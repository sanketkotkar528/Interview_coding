{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2789bb8b",
   "metadata": {},
   "source": [
    "In Data Structures and Algorithms (DSA), \"complexity\" refers to how the resources (time and space) required by an algorithm or data structure operation scale with the size of the input. Analyzing complexity helps us predict performance and choose the most efficient approach for a given problem.\n",
    "\n",
    "\n",
    "There are two main types of complexities:\n",
    "\n",
    "1. Time Complexity: This measures the amount of time an algorithm takes to run as a function of the input size (usually denoted as 'n'). It quantifies how the execution time grows as 'n' increases.\n",
    "\n",
    "\n",
    "2. Space Complexity: This measures the amount of memory space an algorithm or data structure operation requires to run as a function of the input size. It quantifies how the memory usage grows as 'n' increases.\n",
    "\n",
    "\n",
    "Both time and space complexity are typically expressed using Asymptotic Notations, which describe the limiting behavior of the function as the input size 'n' approaches infinity. These notations allow us to classify algorithms based on their growth rates, ignoring constant factors and lower-order terms.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c5fda8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd15c6fc",
   "metadata": {},
   "source": [
    "Asymptotic Notations:\n",
    "There are three primary asymptotic notations:\n",
    "\n",
    "1. Big O Notation (O-notation) - Upper Bound / Worst-Case:\n",
    "\n",
    "-    Purpose: Describes the upper bound or the worst-case time/space complexity of an algorithm. It tells you the maximum amount of time or space an algorithm will ever take for a given input size.\n",
    "\n",
    "-   Meaning: If an algorithm has a complexity of O(f(n)), it means that for sufficiently large n, the running time/space will not grow faster than c⋅f(n) for some constant c.\n",
    "\n",
    "-   Example: A linear search has a worst-case time complexity of O(n) because, in the worst case, you might have to check every element in the list.\n",
    "\n",
    "2. Big Omega Notation (Ω-notation) - Lower Bound / Best-Case:\n",
    "\n",
    "-   Purpose: Describes the lower bound or the best-case time/space complexity of an algorithm. It tells you the minimum amount of time or space an algorithm will take.\n",
    "\n",
    "-   Meaning: If an algorithm has a complexity of Ω(f(n)), it means that for sufficiently large n, the running time/space will not grow slower than c⋅f(n) for some constant c.\n",
    "\n",
    "-   Example: A linear search has a best-case time complexity of Ω(1) if the element you're looking for is the very first one in the list.\n",
    "\n",
    "3. Big Theta Notation (Θ-notation) - Tight Bound / Average-Case:\n",
    "\n",
    "-   Purpose: Describes the tight bound or average-case time/space complexity. It indicates that the algorithm's performance is bounded both from above and below by the same function.\n",
    "\n",
    "-   Meaning: If an algorithm has a complexity of Θ(f(n)), it means that for sufficiently large n, the running time/space is essentially proportional to f(n). It implies that the best-case and worst-case complexities are the same, or at least of the same order of magnitude.\n",
    "\n",
    "-   Example: Merge Sort has a time complexity of Θ(nlogn) because its performance is consistently nlogn in best, average, and worst cases.\n",
    "\n",
    "---\n",
    "**Common Complexity Classes (from best to worst)**:\n",
    "When you see complexities like O(1), O(logn), etc., these represent different growth rates:\n",
    "\n",
    "- O(1) - Constant Time/Space:\n",
    "\n",
    "-       The time/space required is constant, regardless of the input size.\n",
    "-       Example: Accessing an element in an array by its index.\n",
    "\n",
    "- O(logn) - Logarithmic Time/Space:\n",
    "\n",
    "-       The time/space grows very slowly as the input size increases. Often seen in algorithms that divide the problem into halves repeatedly.\n",
    "-       Example: Binary search in a sorted array.\n",
    "\n",
    "\n",
    "- O(n) - Linear Time/Space:\n",
    "\n",
    "-       The time/space grows directly proportional to the input size.\n",
    "\n",
    "-       Example: Traversing a list, searching for an element in an unsorted list.\n",
    "\n",
    "\n",
    "- O(nlogn) - Linearithmic Time/Space:\n",
    "\n",
    "-       A bit slower than linear but much faster than quadratic. Common in efficient sorting algorithms.\n",
    "\n",
    "-       Example: Merge Sort, Quick Sort (average case), Heap Sort.\n",
    "\n",
    "\n",
    "-  O(n \n",
    "2\n",
    " ) - Quadratic Time/Space:\n",
    "\n",
    "-       The time/space grows proportionally to the square of the input size. Often seen with nested loops.\n",
    "\n",
    "-       Example: Bubble Sort, Insertion Sort (worst case), comparing every element to every other element.\n",
    "\n",
    "\n",
    "-  O(n \n",
    "k\n",
    " ) - Polynomial Time/Space:\n",
    "\n",
    "-       Generalizes quadratic; includes O(n 3 ), O(n 4 ), etc.\n",
    "\n",
    "-       Example: Algorithms with multiple nested loops.\n",
    "\n",
    "\n",
    "- O(2n) - Exponential Time/Space:\n",
    "\n",
    "-       The time/space doubles with each additional input. Very slow for even moderately sized inputs.\n",
    "\n",
    "-       Example: Brute-force solutions to problems like the Traveling Salesperson Problem, recursive Fibonacci calculation without memoization.\n",
    "\n",
    "\n",
    "- O(n!) - Factorial Time/Space:\n",
    "\n",
    "-       Extremely slow, typically involves permutations.\n",
    "\n",
    "-       Example: Solving the Traveling Salesperson Problem by trying all permutations.\n",
    "\n",
    "\n",
    "---\n",
    "**Understanding these complexities is fundamental in DSA because it allows you to**:\n",
    "\n",
    "- Predict performance: Estimate how an algorithm will behave with larger inputs.\n",
    "\n",
    "- Compare algorithms: Choose the most efficient algorithm for a specific task.\n",
    "\n",
    "- Optimize code: Identify bottlenecks and improve inefficient parts of your program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10111fca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
