{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bd8713",
   "metadata": {},
   "source": [
    "# Pandas Operations\n",
    "\n",
    "- In this file you will find all the basic and common opearation performed with the help pf Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be183fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c02a08",
   "metadata": {},
   "source": [
    "### Create a Series\n",
    "\n",
    "- There are multiple ways by which we can create the Series\n",
    "1. using list\n",
    "2. using numpy array\n",
    "3. using dictionary\n",
    "4. from scalar value\n",
    "5. from a range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "021c16c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using list\n",
    "data_list = [1,2,3,4,5]\n",
    "series_from_list = pd.Series(data_list)\n",
    "print(series_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f28d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    3\n",
      "2    2\n",
      "3    4\n",
      "4    5\n",
      "5    5\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Using Numpy array\n",
    "numpy_array = np.array([1,3,2,4,5,5])\n",
    "series_from_array = pd.Series(numpy_array)\n",
    "print(series_from_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95dcc04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# From Dictionary\n",
    "data_dict = {'a':1,'b':2,'c':3}\n",
    "series_from_dict = pd.Series(data_dict)\n",
    "print(series_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3ebd2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    5\n",
      "b    5\n",
      "c    5\n",
      "d    5\n",
      "e    5\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# From scalar value\n",
    "scalar_value = 5\n",
    "index_label = ['a','b','c','d','e']\n",
    "series_from_scalar = pd.Series(scalar_value, index=index_label)\n",
    "print(series_from_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ecd0c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     0\n",
      "1    10\n",
      "2    20\n",
      "3    30\n",
      "4    40\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# From a Range\n",
    "start = 0\n",
    "stop = 50\n",
    "step = 10\n",
    "series_range = pd.Series(pd.RangeIndex(start,stop,step))\n",
    "print(series_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffca839",
   "metadata": {},
   "source": [
    "### Create the DataFrame\n",
    "\n",
    "- There are multiple ways to create the `DataFrame`\n",
    "1. From Dictionary of list or arrays\n",
    "2. From lists of dictionary\n",
    "3. From list of lists or arrays with column and Index Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85f093d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Gender\n",
      "0     John   25    Male\n",
      "1     Emma   30  Female\n",
      "2    James   35    Male\n",
      "3   Olivia   40  Female\n",
      "4  William   45    Male\n"
     ]
    }
   ],
   "source": [
    "# From dictionary of lists or arrays\n",
    "data = {'Name': ['John', 'Emma', 'James', 'Olivia', 'William'],\n",
    "        'Age': [25, 30, 35, 40, 45],\n",
    "        'Gender': ['Male', 'Female', 'Male', 'Female', 'Male']}\n",
    "df_from_dict = pd.DataFrame(data)\n",
    "print(df_from_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce80b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Gender\n",
      "0     John   25    Male\n",
      "1     Emma   30  Female\n",
      "2    James   35    Male\n",
      "3   Olivia   40  Female\n",
      "4  William   45    Male\n"
     ]
    }
   ],
   "source": [
    "# From list of dictionary\n",
    "\n",
    "data = [{'Name': 'John', 'Age': 25, 'Gender': 'Male'},\n",
    "        {'Name': 'Emma', 'Age': 30, 'Gender': 'Female'},\n",
    "        {'Name': 'James', 'Age': 35, 'Gender': 'Male'},\n",
    "        {'Name': 'Olivia', 'Age': 40, 'Gender': 'Female'},\n",
    "        {'Name': 'William', 'Age': 45, 'Gender': 'Male'}]\n",
    "df_from_list_of_dicts = pd.DataFrame(data)\n",
    "print(df_from_list_of_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ef0017a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Gender\n",
      "A     John   25    Male\n",
      "B     Emma   30  Female\n",
      "C    James   35    Male\n",
      "D   Olivia   40  Female\n",
      "E  William   45    Male\n"
     ]
    }
   ],
   "source": [
    "# From list of lists or arrays with column and Index labels\n",
    "\n",
    "data = [['John', 25, 'Male'],\n",
    "        ['Emma', 30, 'Female'],\n",
    "        ['James', 35, 'Male'],\n",
    "        ['Olivia', 40, 'Female'],\n",
    "        ['William', 45, 'Male']]\n",
    "columns = ['Name', 'Age', 'Gender']\n",
    "index = ['A', 'B', 'C', 'D', 'E']\n",
    "df_from_list_of_lists = pd.DataFrame(data, columns=columns, index=index)\n",
    "print(df_from_list_of_lists)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef93998",
   "metadata": {},
   "source": [
    "### Add rows in the existing Dataframe\n",
    "- There are multiple ways to create the Dataframe\n",
    "1. using appending rows to dataframe\n",
    "    - As this append function is going to be removed from the latest version of the pandas library, it is suggested that no to use this function\n",
    "2. Using loc method\n",
    "2. using concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7aabff",
   "metadata": {},
   "source": [
    "- **append**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400548dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Gender\n",
      "0    John   25    Male\n",
      "1    Emma   30  Female\n",
      "2   James   35    Male\n",
      "3  Olivia   40  Female\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanke\\AppData\\Local\\Temp\\ipykernel_55824\\4121359596.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(new_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# We can add multiple rows by using this append function\n",
    "\n",
    "# Existing DataFrame\n",
    "data = {'Name': ['John', 'Emma', 'James'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'Gender': ['Male', 'Female', 'Male']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dictionary representing the new row\n",
    "new_row = {'Name': 'Olivia', 'Age': 40, 'Gender': 'Female'}\n",
    "\n",
    "# Appending the new row\n",
    "df = df.append(new_row, ignore_index=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7dc74",
   "metadata": {},
   "source": [
    "- **iloc**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c556da06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Gender\n",
      "0    John   25    Male\n",
      "1    Emma   30  Female\n",
      "2   James   35    Male\n",
      "3  Olivia   40  Female\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Existing DataFrame\n",
    "data = {'Name': ['John', 'Emma', 'James'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'Gender': ['Male', 'Female', 'Male']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Adding a row using loc\n",
    "df.loc[3] = ['Olivia', 40, 'Female']\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042894e8",
   "metadata": {},
   "source": [
    "- **using concat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cfeabb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Name  Age  Gender\n",
      "0    John   25    Male\n",
      "1    Emma   30  Female\n",
      "2   James   35    Male\n",
      "0  Olivia   40  Female\n"
     ]
    }
   ],
   "source": [
    "# Using the concat function\n",
    "\n",
    "# Existing DataFrame\n",
    "data = {'Name': ['John', 'Emma', 'James'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'Gender': ['Male', 'Female', 'Male']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dictionary representing the new row\n",
    "new_row = {'Name': ['Olivia'], 'Age': [40], 'Gender': ['Female']}\n",
    "temp = pd.DataFrame(new_row)\n",
    "\n",
    "# Concating the dataframe\n",
    "df = pd.concat([df, temp])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7586a",
   "metadata": {},
   "source": [
    "### Data Loading and Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cf39b",
   "metadata": {},
   "source": [
    "- Load the SQL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b50205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laoding the SQL data into pandas dataframe\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# Establishing a connection to the SQL database\n",
    "conn = sqlite3.connect('your_database.db')  # Replace 'your_database.db' with the path to your SQLite database\n",
    "# If you are using a different SQL database like MySQL, PostgreSQL, etc.,\n",
    "# you would need to use appropriate connection parameters and libraries for that specific database.\n",
    "\n",
    "# Writing your SQL query\n",
    "query = \"SELECT * FROM your_table;\"  # Replace 'your_table' with the name of the table you want to query\n",
    "\n",
    "# Loading data into a DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Closing the database connection\n",
    "conn.close()\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be485e11",
   "metadata": {},
   "source": [
    "- Load the html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399a375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading HTML file into a list of DataFrames\n",
    "dfs = pd.read_html('your_file.html')  # Replace 'your_file.html' with the path to your HTML file\n",
    "\n",
    "# Accessing the DataFrame(s) from the list\n",
    "for i, df in enumerate(dfs):\n",
    "    print(f\"DataFrame {i + 1}:\")\n",
    "    print(df)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f52668",
   "metadata": {},
   "source": [
    "- Load the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a410df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading JSON file into a DataFrame\n",
    "df = pd.read_json('your_file.json')  # Replace 'your_file.json' with the path to your JSON file\n",
    "\n",
    "# Displaying the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050fcfbb",
   "metadata": {},
   "source": [
    "### Reshape the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f29167",
   "metadata": {},
   "source": [
    "- Pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19806766",
   "metadata": {},
   "source": [
    "**pivot(): Reshape data based on column values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31c0e6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City        Chicago  Los Angeles  New York\n",
      "Date                                      \n",
      "2022-01-01      NaN          NaN      32.0\n",
      "2022-01-02      NaN         75.0       NaN\n",
      "2022-01-03     50.0          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Creating a DataFrame\n",
    "data = {'Date': ['2022-01-01', '2022-01-02', '2022-01-03'],\n",
    "        'City': ['New York', 'Los Angeles', 'Chicago'],\n",
    "        'Temperature': [32, 75, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Reshaping using pivot\n",
    "pivot_df = df.pivot(index='Date', columns='City', values='Temperature')\n",
    "print(pivot_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7ec34",
   "metadata": {},
   "source": [
    "**pivot_table(): Reshape data while handling duplicate entries by aggregating values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "310d0320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City        Chicago  Los Angeles  New York\n",
      "Date                                      \n",
      "2022-01-01      NaN          NaN      32.0\n",
      "2022-01-02      NaN         75.0       NaN\n",
      "2022-01-03     50.0          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Using pivot_table\n",
    "pivot_table_df = df.pivot_table(index='Date', columns='City', values='Temperature', aggfunc='mean')\n",
    "print(pivot_table_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a130045",
   "metadata": {},
   "source": [
    "**stack(): Reshape data by pivoting the innermost level of column labels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "371416ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date        City       \n",
      "2022-01-01  New York       32.0\n",
      "2022-01-02  Los Angeles    75.0\n",
      "2022-01-03  Chicago        50.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Using stack\n",
    "stacked_df = pivot_df.stack()\n",
    "print(stacked_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ae714",
   "metadata": {},
   "source": [
    "**unstack(): Reverse the operation of stack, pivoting the innermost level of row labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9859d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City        Chicago  Los Angeles  New York\n",
      "Date                                      \n",
      "2022-01-01      NaN          NaN      32.0\n",
      "2022-01-02      NaN         75.0       NaN\n",
      "2022-01-03     50.0          NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Using unstack\n",
    "unstacked_df = stacked_df.unstack()\n",
    "print(unstacked_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf9c97c",
   "metadata": {},
   "source": [
    "### Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9f4123b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "0  1   4\n",
      "1  2   5\n",
      "2  3   6\n",
      "0  7  10\n",
      "1  8  11\n",
      "2  9  12\n"
     ]
    }
   ],
   "source": [
    "# Creating two DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3],\n",
    "                    'B': [4, 5, 6]})\n",
    "df2 = pd.DataFrame({'A': [7, 8, 9],\n",
    "                    'B': [10, 11, 12]})\n",
    "\n",
    "# Concatenating along rows\n",
    "result = pd.concat([df1, df2], axis=0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f53f24",
   "metadata": {},
   "source": [
    "### Merge\n",
    "\n",
    "- Merge function is based on the column's values. It allows you to merge the dataframe based on common columns or columns with different names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae15336c",
   "metadata": {},
   "source": [
    "- Inner Merge : An inner merge returns only the rows that have matching values in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39a3d701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_x  value_y\n",
      "0   B        2        5\n",
      "1   D        4        6\n"
     ]
    }
   ],
   "source": [
    "# Creating two DataFrames\n",
    "df1 = pd.DataFrame({'key': ['A', 'B', 'C', 'D'],\n",
    "                    'value': [1, 2, 3, 4]})\n",
    "df2 = pd.DataFrame({'key': ['B', 'D', 'E', 'F'],\n",
    "                    'value': [5, 6, 7, 8]})\n",
    "\n",
    "# Performing inner merge\n",
    "inner_merge = pd.merge(df1, df2, on='key', how='inner')\n",
    "print(inner_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12d6ff",
   "metadata": {},
   "source": [
    "- Left merge : A left merge returns all the rows from the left DataFrame and the matched rows from the right DataFrame. If there is no match, NaN values are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "655272fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_x  value_y\n",
      "0   A        1      NaN\n",
      "1   B        2      5.0\n",
      "2   C        3      NaN\n",
      "3   D        4      6.0\n"
     ]
    }
   ],
   "source": [
    "# Performing left merge\n",
    "left_merge = pd.merge(df1, df2, on='key', how='left')\n",
    "print(left_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906a37b",
   "metadata": {},
   "source": [
    "- Right Merge : A right merge returns all the rows from the right DataFrame and the matched rows from the left DataFrame. If there is no match, NaN values are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df315ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_x  value_y\n",
      "0   B      2.0        5\n",
      "1   D      4.0        6\n",
      "2   E      NaN        7\n",
      "3   F      NaN        8\n"
     ]
    }
   ],
   "source": [
    "# Performing right merge\n",
    "right_merge = pd.merge(df1, df2, on='key', how='right')\n",
    "print(right_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f734c831",
   "metadata": {},
   "source": [
    "- Outer Merge : An outer merge returns all the rows from both DataFrames and fills in NaN values for missing matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd251a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key  value_x  value_y\n",
      "0   A      1.0      NaN\n",
      "1   B      2.0      5.0\n",
      "2   C      3.0      NaN\n",
      "3   D      4.0      6.0\n",
      "4   E      NaN      7.0\n",
      "5   F      NaN      8.0\n"
     ]
    }
   ],
   "source": [
    "# Performing outer merge\n",
    "outer_merge = pd.merge(df1, df2, on='key', how='outer')\n",
    "print(outer_merge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9414031",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "- Join is based on the indexes of the dataframe. It allows you to join the Dataframes based on theie Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a8dbe",
   "metadata": {},
   "source": [
    "- **Left Join**: Returns all the rows from the left DataFrame and the matched rows from the right DataFrame. If there is no match, NaN values are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a826598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left join:\n",
      "   A    B\n",
      "a  1  NaN\n",
      "b  2  4.0\n",
      "c  3  5.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating two DataFrames\n",
    "df1 = pd.DataFrame({'A': [1, 2, 3]}, index=['a', 'b', 'c'])\n",
    "df2 = pd.DataFrame({'B': [4, 5, 6]}, index=['b', 'c', 'd'])\n",
    "\n",
    "# Left join\n",
    "left_join = df1.join(df2, how='left')\n",
    "print(\"Left join:\")\n",
    "print(left_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e850c6",
   "metadata": {},
   "source": [
    "- **Right Join**: Returns all the rows from the right DataFrame and the matched rows from the left DataFrame. If there is no match, NaN values are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4106fef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Right join:\n",
      "     A  B\n",
      "b  2.0  4\n",
      "c  3.0  5\n",
      "d  NaN  6\n"
     ]
    }
   ],
   "source": [
    "# Right join\n",
    "right_join = df1.join(df2, how='right')\n",
    "print(\"\\nRight join:\")\n",
    "print(right_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b727f48",
   "metadata": {},
   "source": [
    "- **Inner Join**: Returns only the rows that have matching index values in both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f96dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner join:\n",
      "   A  B\n",
      "b  2  4\n",
      "c  3  5\n"
     ]
    }
   ],
   "source": [
    "# Inner join\n",
    "inner_join = df1.join(df2, how='inner')\n",
    "print(\"\\nInner join:\")\n",
    "print(inner_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4b189",
   "metadata": {},
   "source": [
    "- **Outer Join** : Returns all the rows from both DataFrames and fills in NaN values for missing matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a60cccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outer join:\n",
      "     A    B\n",
      "a  1.0  NaN\n",
      "b  2.0  4.0\n",
      "c  3.0  5.0\n",
      "d  NaN  6.0\n"
     ]
    }
   ],
   "source": [
    "# Outer join\n",
    "outer_join = df1.join(df2, how='outer')\n",
    "print(\"\\nOuter join:\")\n",
    "print(outer_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60baca",
   "metadata": {},
   "source": [
    "### Selection of dataframe using iloc and loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2522c9b",
   "metadata": {},
   "source": [
    "- **iloc**:\n",
    "    - iloc is used for integer-based indexing. \n",
    "    - It is primarily used when you want to access DataFrame elements by their integer position.\n",
    "    - You specify the row and column indices using integers, starting from 0.\n",
    "    - The syntax for iloc is df.iloc[row_index, column_index]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e11f67d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using iloc:\n",
      "4\n",
      "A    2\n",
      "B    5\n",
      "C    8\n",
      "Name: Y, dtype: int64\n",
      "X    7\n",
      "Y    8\n",
      "Z    9\n",
      "Name: C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'A': [1, 2, 3],\n",
    "        'B': [4, 5, 6],\n",
    "        'C': [7, 8, 9]}\n",
    "df = pd.DataFrame(data, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Using iloc to access data by integer position\n",
    "print(\"Using iloc:\")\n",
    "print(df.iloc[0, 1])  # Accessing element at row 0, column 1 (value: 4)\n",
    "print(df.iloc[1])     # Accessing entire row at index 1 (row 'Y')\n",
    "print(df.iloc[:, 2])  # Accessing entire column at index 2 (column 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0cf97",
   "metadata": {},
   "source": [
    "- **loc**:\n",
    "\n",
    "    - loc is used for label-based indexing. It is primarily used when you want to access DataFrame elements by their row and column labels.\n",
    "    - You specify the row and column labels directly.\n",
    "    - The syntax for loc is df.loc[row_label, column_label]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5757594e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using loc:\n",
      "4\n",
      "A    2\n",
      "B    5\n",
      "C    8\n",
      "Name: Y, dtype: int64\n",
      "X    7\n",
      "Y    8\n",
      "Z    9\n",
      "Name: C, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Using loc to access data by label\n",
    "print(\"\\nUsing loc:\")\n",
    "print(df.loc['X', 'B'])  # Accessing element at row 'X', column 'B' (value: 4)\n",
    "print(df.loc['Y'])     # Accessing entire row with label 'Y'\n",
    "print(df.loc[:, 'C'])  # Accessing entire column with label 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a501fd",
   "metadata": {},
   "source": [
    "### Filtering the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77e2c75",
   "metadata": {},
   "source": [
    "- **Boolean Indexing** : Use boolean expressions to filter rows based on conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "625dc29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "2  3  c\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': ['a', 'b', 'c', 'd', 'e']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filtering rows where values in column 'A' are greater than 2\n",
    "filtered_df = df[df['A'] > 2]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c60d1",
   "metadata": {},
   "source": [
    "- **Query Method** : Use the query() method to filter rows based on a query string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3155595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "2  3  c\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows where values in column 'A' are greater than 2 using query method\n",
    "filtered_df = df.query('A > 2')\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c887e2c5",
   "metadata": {},
   "source": [
    "- **loc Method** : Use the loc[] method to filter rows based on labels or boolean arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03982b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "2  3  c\n",
      "3  4  d\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows where values in column 'A' are greater than 2 using loc method\n",
    "filtered_df = df.loc[df['A'] > 2]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5cd626",
   "metadata": {},
   "source": [
    "- **isin Method**: Use the isin() method to filter rows based on whether values are in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6982ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  a\n",
      "2  3  c\n",
      "4  5  e\n"
     ]
    }
   ],
   "source": [
    "# Filtering rows where values in column 'B' are in a list\n",
    "filtered_df = df[df['B'].isin(['a', 'c', 'e'])]\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2516146",
   "metadata": {},
   "source": [
    "- **Filtering Columns** : Use column indexing or the filter() method to filter columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "914f1e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A\n",
      "0  1\n",
      "1  2\n",
      "2  3\n",
      "3  4\n",
      "4  5\n",
      "\n",
      "   B\n",
      "0  a\n",
      "1  b\n",
      "2  c\n",
      "3  d\n",
      "4  e\n"
     ]
    }
   ],
   "source": [
    "# Filtering columns based on column names\n",
    "filtered_columns = df[['A']]\n",
    "print( filtered_columns)\n",
    "print()\n",
    "# Filtering columns using the filter method\n",
    "filtered_columns = df.filter(items=['B'])\n",
    "print(filtered_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa39cf",
   "metadata": {},
   "source": [
    "### Sorting Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7b1415",
   "metadata": {},
   "source": [
    "- **sort_values()**: Use the sort_values() method to sort the DataFrame based on the values in one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11891cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by column 'A' ascending:\n",
      "   A  B\n",
      "2  1  a\n",
      "1  2  b\n",
      "0  3  c\n",
      "3  4  d\n",
      "4  5  e\n",
      "\n",
      "\n",
      "Sorted by column 'A' descending:\n",
      "   A  B\n",
      "4  5  e\n",
      "3  4  d\n",
      "0  3  c\n",
      "1  2  b\n",
      "2  1  a\n"
     ]
    }
   ],
   "source": [
    "# Creating a sample DataFrame\n",
    "data = {'A': [3, 2, 1, 4, 5],\n",
    "        'B': ['c', 'b', 'a', 'd', 'e']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sorting the DataFrame by values in column 'A' (ascending order)\n",
    "sorted_df = df.sort_values(by='A')\n",
    "print(\"Sorted by column 'A' ascending:\")\n",
    "print(sorted_df)\n",
    "print()\n",
    "\n",
    "# Sorting the DataFrame by values in column 'A' (descending order)\n",
    "sorted_df_desc = df.sort_values(by='A', ascending=False)\n",
    "print(\"\\nSorted by column 'A' descending:\")\n",
    "print(sorted_df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfabf1ac",
   "metadata": {},
   "source": [
    "- Sort the DataFrame considering multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eed740ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by columns 'A' ascending and 'B' descending:\n",
      "   A  B   C\n",
      "2  1  a  15\n",
      "3  2  d  25\n",
      "1  2  b  20\n",
      "0  3  c  10\n",
      "4  5  e  30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "data = {'A': [3, 2, 1, 2, 5],\n",
    "        'B': ['c', 'b', 'a', 'd', 'e'],\n",
    "        'C': [10, 20, 15, 25, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sorting the DataFrame by values in column 'A' (ascending) and then by values in column 'B' (descending)\n",
    "sorted_df = df.sort_values(by=['A', 'B'], ascending=[True, False])\n",
    "print(\"Sorted by columns 'A' ascending and 'B' descending:\")\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb8752c",
   "metadata": {},
   "source": [
    "- **sort_index()** : Use the sort_index() method to sort the DataFrame based on its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86f18881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sorted by index ascending:\n",
      "   A  B\n",
      "0  3  c\n",
      "1  2  b\n",
      "2  1  a\n",
      "3  4  d\n",
      "4  5  e\n",
      "\n",
      "Sorted by index descending:\n",
      "   A  B\n",
      "4  5  e\n",
      "3  4  d\n",
      "2  1  a\n",
      "1  2  b\n",
      "0  3  c\n"
     ]
    }
   ],
   "source": [
    "# Sorting the DataFrame by index (ascending order)\n",
    "sorted_index_df = df.sort_index()\n",
    "print(\"\\nSorted by index ascending:\")\n",
    "print(sorted_index_df)\n",
    "\n",
    "# Sorting the DataFrame by index (descending order)\n",
    "sorted_index_df_desc = df.sort_index(ascending=False)\n",
    "print(\"\\nSorted by index descending:\")\n",
    "print(sorted_index_df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8491e83",
   "metadata": {},
   "source": [
    "### Detect NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f6fba",
   "metadata": {},
   "source": [
    "- **isna() / isnull()** : These methods return a DataFrame of boolean values indicating whether each element is a missing value or not. You can then use methods like any() or sum() to identify columns with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd759119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    True\n",
      "B    True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, 2, None, 4],\n",
    "        'B': [5, None, 7, 8]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values in each column\n",
    "na_columns = df.isna().any()\n",
    "print(na_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66042054",
   "metadata": {},
   "source": [
    "- **info()**: The info() method provides a concise summary of the DataFrame, including the count of non-null values in each column. Columns with missing values will have a lower count than the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "525c2329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   A       3 non-null      float64\n",
      " 1   B       3 non-null      float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 192.0 bytes\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a51649",
   "metadata": {},
   "source": [
    "- **describe()**: The describe() method provides summary statistics for numerical columns, including the count of non-null values. Columns with missing values will have a count lower than the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b768d889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.333333</td>\n",
       "      <td>6.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.527525</td>\n",
       "      <td>1.527525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.500000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              A         B\n",
       "count  3.000000  3.000000\n",
       "mean   2.333333  6.666667\n",
       "std    1.527525  1.527525\n",
       "min    1.000000  5.000000\n",
       "25%    1.500000  6.000000\n",
       "50%    2.000000  7.000000\n",
       "75%    3.000000  7.500000\n",
       "max    4.000000  8.000000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b2bc72",
   "metadata": {},
   "source": [
    "-  **notna() / notnull()**: These methods are the complement of isna() / isnull(), returning the opposite boolean values. You can use them to identify columns without missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcfb89ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    False\n",
      "B    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Check for non-missing values in each column\n",
    "non_na_columns = df.notna().all()\n",
    "print(non_na_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c55d57d",
   "metadata": {},
   "source": [
    "### Dropping NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd16614",
   "metadata": {},
   "source": [
    "- **dropna()**: The dropna() method is used to remove rows or columns with missing values from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6748f9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, None, 3],\n",
    "        'B': [4, 5, None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Remove rows with any NA values\n",
    "cleaned_df = df.dropna()\n",
    "print(cleaned_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96377030",
   "metadata": {},
   "source": [
    "### Fill Na Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2df4be",
   "metadata": {},
   "source": [
    "- **fillna()**: The fillna() method is used to fill missing values with specified values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a7b77",
   "metadata": {},
   "source": [
    "    - Filling missing values with a constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "344a5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  0.0  5.0\n",
      "2  3.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a sample DataFrame with missing values\n",
    "data = {'A': [1, None, 3],\n",
    "        'B': [4, 5, None]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill missing values with a constant (e.g., 0)\n",
    "filled_df = df.fillna(0)\n",
    "print(filled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc6dc92",
   "metadata": {},
   "source": [
    "    - Filling missing values with the mean of the column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292e0bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  3.0  4.5\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values with the mean of the column\n",
    "filled_df = df.fillna(df.mean())\n",
    "print(filled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544911c",
   "metadata": {},
   "source": [
    "- **ffill() / bfill()**: The ffill() method fills missing values using the previous valid value (forward fill), while the bfill() method fills missing values using the next valid value (backward fill)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe157cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  1.0  5.0\n",
      "2  3.0  5.0\n",
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  3.0  5.0\n",
      "2  3.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# Forward fill missing values\n",
    "filled_df_ffill = df.ffill()\n",
    "print(filled_df_ffill)\n",
    "\n",
    "# Backward fill missing values\n",
    "filled_df_bfill = df.bfill()\n",
    "print(filled_df_bfill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28627f17",
   "metadata": {},
   "source": [
    "- **interpolate()**: The interpolate() method fills missing values by interpolating between existing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568ea092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  3.0  5.0\n"
     ]
    }
   ],
   "source": [
    "# Interpolate missing values\n",
    "interpolated_df = df.interpolate()\n",
    "print(interpolated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3cd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b35c7501",
   "metadata": {},
   "source": [
    "### Groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3b06c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Grade\n",
      "Subject       \n",
      "Math     82.50\n",
      "Science  85.25\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Math', 'Math', 'Math', 'Science', 'Science', 'Science', 'Science'],\n",
    "    'Grade': [85, 90, 75, 80, 95, 70, 88, 92, 78, 83]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the DataFrame by 'Subject'\n",
    "grouped_df = df.groupby('Subject').mean()\n",
    "\n",
    "print(grouped_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558909d7",
   "metadata": {},
   "source": [
    "- **agg() Method**: Used to compute aggregations (summary statistics) for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebd61013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Grade        \n",
      "          mean max min\n",
      "Subject               \n",
      "Math     82.50  95  70\n",
      "Science  85.25  92  78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Math', 'Math', 'Math', 'Science', 'Science', 'Science', 'Science'],\n",
    "    'Grade': [85, 90, 75, 80, 95, 70, 88, 92, 78, 83]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the DataFrame by 'Subject' and calculate multiple aggregations\n",
    "aggregated_data = df.groupby('Subject').agg({\n",
    "    'Grade': ['mean', 'max', 'min']\n",
    "})\n",
    "\n",
    "print(aggregated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e13fb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Value\n",
      "Category                                         \n",
      "A         {'Mean': 18.333333333333332, 'Sum': 55}\n",
      "B                       {'Mean': 22.5, 'Sum': 45}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a sample DataFrame\n",
    "data = {'Category': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Value': [10, 20, 15, 25, 30]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a custom aggregation function\n",
    "def my_agg_func(x):\n",
    "    return {'Mean': x.mean(), 'Sum': x.sum()}\n",
    "\n",
    "# Group by 'Category' column and apply custom aggregation function\n",
    "grouped = df.groupby('Category').agg(my_agg_func)\n",
    "print(grouped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "638fc85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Grade        \n",
      "                     mean max min\n",
      "Subject Gender                   \n",
      "Math    F       86.666667  95  80\n",
      "        M       78.333333  90  70\n",
      "Science F       85.500000  88  83\n",
      "        M       85.000000  92  78\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Math', 'Math', 'Math', 'Science', 'Science', 'Science', 'Science'],\n",
    "    'Gender': ['F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F'],\n",
    "    'Grade': [85, 90, 75, 80, 95, 70, 88, 92, 78, 83]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the DataFrame by 'Subject' and 'Gender' and calculate multiple aggregations\n",
    "aggregated_data = df.groupby(['Subject', 'Gender']).agg({\n",
    "    'Grade': ['mean', 'max', 'min']\n",
    "})\n",
    "\n",
    "print(aggregated_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c8206e",
   "metadata": {},
   "source": [
    "- **transform() Method**: Used to perform transformations on each group independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e029c0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Subject Gender  Grade  Standardized Grade\n",
      "0    Alice     Math      F     85            0.267261\n",
      "1      Bob     Math      M     90            0.801784\n",
      "2  Charlie     Math      M     75           -0.801784\n",
      "3    David     Math      F     80           -0.267261\n",
      "4     Emma     Math      F     95            1.336306\n",
      "5    Frank     Math      M     70           -1.336306\n",
      "6    Alice  Science      F     88            0.452607\n",
      "7      Bob  Science      M     92            1.110945\n",
      "8  Charlie  Science      M     78           -1.193237\n",
      "9    David  Science      F     83           -0.370315\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Math', 'Math', 'Math', 'Science', 'Science', 'Science', 'Science'],\n",
    "    'Gender': ['F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F'],\n",
    "    'Grade': [85, 90, 75, 80, 95, 70, 88, 92, 78, 83]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a custom function for standardization\n",
    "def standardize(x):\n",
    "    return (x - x.mean()) / x.std()\n",
    "\n",
    "# Group the DataFrame by 'Subject' and apply the standardization transformation\n",
    "standardized_grades = df.groupby('Subject')['Grade'].transform(standardize)\n",
    "\n",
    "# Add the standardized grades as a new column to the original DataFrame\n",
    "df['Standardized Grade'] = standardized_grades\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f109f54",
   "metadata": {},
   "source": [
    "- **filter() Method**: Used to filter out groups based on some condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6664706d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student  Subject Gender  Grade\n",
      "6    Alice  Science      F     88\n",
      "7      Bob  Science      M     92\n",
      "8  Charlie  Science      M     78\n",
      "9    David  Science      F     83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Student': ['Alice', 'Bob', 'Charlie', 'David', 'Emma', 'Frank', 'Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Subject': ['Math', 'Math', 'Math', 'Math', 'Math', 'Math', 'Science', 'Science', 'Science', 'Science'],\n",
    "    'Gender': ['F', 'M', 'M', 'F', 'F', 'M', 'F', 'M', 'M', 'F'],\n",
    "    'Grade': [85, 90, 75, 80, 95, 70, 88, 92, 78, 83]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define a custom function to filter groups\n",
    "def filter_low_average(group):\n",
    "    return group['Grade'].mean() >= 85\n",
    "\n",
    "# Group the DataFrame by 'Subject' and filter groups based on average grade\n",
    "filtered_groups = df.groupby('Subject').filter(filter_low_average)\n",
    "\n",
    "print(filtered_groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5878e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9d258ac",
   "metadata": {},
   "source": [
    "### Date Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d5334",
   "metadata": {},
   "source": [
    "In Pandas, you can generate date sequences or ranges using the pd.date_range() function. This function allows you to create a range of dates based on various parameters, such as start date, end date, frequency, and number of periods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea0405",
   "metadata": {},
   "source": [
    "- Generating a Date Range with Start and End Dates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62db1bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n",
      "               '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08',\n",
      "               '2022-01-09', '2022-01-10'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Generate a date range from January 1, 2022 to January 10, 2022\n",
    "date_range = pd.date_range(start='2022-01-01', end='2022-01-10')\n",
    "print(date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c206e",
   "metadata": {},
   "source": [
    "- Generating a Date Range with a Specified Frequency (e.g., daily, monthly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0495ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n",
      "               '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-08',\n",
      "               '2022-01-09', '2022-01-10'],\n",
      "              dtype='datetime64[ns]', freq='D')\n",
      "DatetimeIndex(['2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
      "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
      "               '2022-09-30', '2022-10-31', '2022-11-30', '2022-12-31'],\n",
      "              dtype='datetime64[ns]', freq='M')\n"
     ]
    }
   ],
   "source": [
    "# Generate a date range with daily frequency from January 1, 2022 to January 10, 2022\n",
    "daily_date_range = pd.date_range(start='2022-01-01', end='2022-01-10', freq='D')\n",
    "print(daily_date_range)\n",
    "\n",
    "# Generate a date range with monthly frequency for the year 2022\n",
    "monthly_date_range = pd.date_range(start='2022-01-01', end='2022-12-31', freq='M')\n",
    "print(monthly_date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e3479b",
   "metadata": {},
   "source": [
    "- Generating a Date Range with a Specified Number of Periods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38cc505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04',\n",
      "               '2022-01-05'],\n",
      "              dtype='datetime64[ns]', freq='D')\n"
     ]
    }
   ],
   "source": [
    "# Generate a date range with 5 periods starting from January 1, 2022\n",
    "period_date_range = pd.date_range(start='2022-01-01', periods=5)\n",
    "print(period_date_range)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb4b078",
   "metadata": {},
   "source": [
    "### Date Shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713574a",
   "metadata": {},
   "source": [
    "Date shifting in Pandas refers to the process of shifting (moving) the dates in a time series forward or backward by a specified number of time periods. This can be useful for various time series analysis tasks, such as comparing data points from different time periods, creating lag or lead variables, or aligning data for further analysis.\n",
    "\n",
    "Pandas provides the shift() method to perform date shifting on a Series or DataFrame containing datetime indices.\n",
    "\n",
    "Here's how you can use the shift() method for date shifting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ed47a",
   "metadata": {},
   "source": [
    "- **Shifting Dates Forward**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "574b85ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Values\n",
      "2022-01-01     NaN\n",
      "2022-01-02     NaN\n",
      "2022-01-03    10.0\n",
      "2022-01-04    20.0\n",
      "2022-01-05    30.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with datetime index\n",
    "dates = pd.date_range(start='2022-01-01', periods=5, freq='D')\n",
    "data = {'Values': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data, index=dates)\n",
    "\n",
    "# Shift the dates forward by 2 days\n",
    "shifted_df = df.shift(periods=2)\n",
    "print(shifted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c8defd",
   "metadata": {},
   "source": [
    "- **Shifting Dates Backward**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23614968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Values\n",
      "2022-01-01    20.0\n",
      "2022-01-02    30.0\n",
      "2022-01-03    40.0\n",
      "2022-01-04    50.0\n",
      "2022-01-05     NaN\n"
     ]
    }
   ],
   "source": [
    "# Shift the dates backward by 1 day\n",
    "shifted_df = df.shift(periods=-1)\n",
    "print(shifted_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c265a21",
   "metadata": {},
   "source": [
    "### Frequency Conversion Or Resampling :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b4ce62",
   "metadata": {},
   "source": [
    "\n",
    "Frequency conversion in Pandas refers to the process of changing the frequency of a time series to a different frequency. This can involve upsampling (increasing the frequency) or downsampling (decreasing the frequency) of the data. Frequency conversion is commonly used in time series analysis to resample data to a frequency that is more suitable for analysis or visualization.\n",
    "\n",
    "Pandas provides the resample() method for frequency conversion. This method allows you to specify the new frequency and apply an aggregation function to the data if necessary.\n",
    "\n",
    "Here's how you can use the resample() method for frequency conversion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c0fbe",
   "metadata": {},
   "source": [
    "- **Downsampling: Decreasing the Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "479729d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Values\n",
      "2022-01-02     0.5\n",
      "2022-01-09     5.0\n",
      "2022-01-16     9.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame with datetime index\n",
    "dates = pd.date_range(start='2022-01-01', periods=10, freq='D')\n",
    "data = {'Values': range(10)}\n",
    "df = pd.DataFrame(data, index=dates)\n",
    "\n",
    "# Downsample the data from daily to weekly frequency, taking the mean value for each week\n",
    "downsampled_df = df.resample('W').mean()\n",
    "print(downsampled_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb73ad",
   "metadata": {},
   "source": [
    "- **Upsampling: Increasing the Frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e61d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Values\n",
      "2022-01-01 00:00:00  0.000000\n",
      "2022-01-01 01:00:00  0.041667\n",
      "2022-01-01 02:00:00  0.083333\n",
      "2022-01-01 03:00:00  0.125000\n",
      "2022-01-01 04:00:00  0.166667\n",
      "2022-01-01 05:00:00  0.208333\n",
      "2022-01-01 06:00:00  0.250000\n",
      "2022-01-01 07:00:00  0.291667\n",
      "2022-01-01 08:00:00  0.333333\n",
      "2022-01-01 09:00:00  0.375000\n"
     ]
    }
   ],
   "source": [
    "# Upsample the data from daily to hourly frequency, filling missing values with interpolation\n",
    "upsampled_df = df.resample('H').interpolate()\n",
    "print(upsampled_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44760f45",
   "metadata": {},
   "source": [
    "### Converting Categorical data to Numerical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee6c23a",
   "metadata": {},
   "source": [
    "\n",
    "Pandas provides several methods for converting categorical data to numerical data, which is essential for many machine learning algorithms that only accept numerical inputs. \n",
    "\n",
    "Here are some common methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dc5d17",
   "metadata": {},
   "source": [
    "- **Label Encoding**: Label encoding assigns a unique integer to each category in a categorical variable. It is suitable for ordinal categorical data where there is an inherent order among categories. Pandas provides the cat.codes attribute to perform label encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53f44c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Category_LabelEncoded\n",
      "0        A                      0\n",
      "1        B                      1\n",
      "2        C                      2\n",
      "3        A                      0\n",
      "4        B                      1\n",
      "5        C                      2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with a categorical variable\n",
    "data = {'Category': ['A', 'B', 'C', 'A', 'B', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform label encoding\n",
    "df['Category_LabelEncoded'] = df['Category'].astype('category').cat.codes\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a179e75f",
   "metadata": {},
   "source": [
    "- **One-Hot Encoding**: One-hot encoding creates binary columns for each category in the variable. Each column indicates the presence or absence of a category in an observation. It is suitable for nominal categorical data where there is no inherent order among categories. Pandas provides the get_dummies() function to perform one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1550f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Category_OneHot_A  Category_OneHot_B  Category_OneHot_C\n",
      "0                  1                  0                  0\n",
      "1                  0                  1                  0\n",
      "2                  0                  0                  1\n",
      "3                  1                  0                  0\n",
      "4                  0                  1                  0\n",
      "5                  0                  0                  1\n"
     ]
    }
   ],
   "source": [
    "# Perform one-hot encoding\n",
    "one_hot_encoded_df = pd.get_dummies(df['Category'], prefix='Category_OneHot')\n",
    "print(one_hot_encoded_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d460ed83",
   "metadata": {},
   "source": [
    "- **Ordinal Encoding**: Ordinal encoding assigns integers to categories based on their order in a predefined list. It is suitable for ordinal categorical data where the categories have a specific order. You can use mapping with a dictionary or custom function to perform ordinal encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2d09e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Category  Category_LabelEncoded  Category_OrdinalEncoded\n",
      "0        A                      0                        1\n",
      "1        B                      1                        2\n",
      "2        C                      2                        3\n",
      "3        A                      0                        1\n",
      "4        B                      1                        2\n",
      "5        C                      2                        3\n"
     ]
    }
   ],
   "source": [
    "# Define a mapping dictionary for ordinal encoding\n",
    "mapping = {'A': 1, 'B': 2, 'C': 3}\n",
    "\n",
    "# Perform ordinal encoding\n",
    "df['Category_OrdinalEncoded'] = df['Category'].map(mapping)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1b0104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9a9050",
   "metadata": {},
   "source": [
    "### dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ec5a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01f90732",
   "metadata": {},
   "source": [
    "### astype()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0709c5",
   "metadata": {},
   "source": [
    "In Pandas, the astype() method is used to cast a pandas object (e.g., DataFrame, Series) to a specified data type. \n",
    "\n",
    "It allows you to convert the data type of the elements within the object to a different data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fec05e",
   "metadata": {},
   "source": [
    "Here's the syntax of the astype() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed37f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.astype(dtype, copy=True, errors='raise')\n",
    "\n",
    "Series.astype(dtype, copy=True, errors='raise')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63e4ef5",
   "metadata": {},
   "source": [
    "    - dtype: Specifies the data type to which the elements will be cast.\n",
    "    - copy: (Optional) Indicates whether to return a copy of the object with the new data type. Default is True.\n",
    "    - errors: (Optional) Specifies how errors should be handled. Possible values are 'raise', 'ignore', and 'coerce'. Default is 'raise'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce212d40",
   "metadata": {},
   "source": [
    "- **Changing Data Types**: You can use astype() to change the data type of a DataFrame or Series to another data type. For example, converting numerical data to string or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f44bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    float64\n",
      "B      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Convert integer values in column 'A' to float\n",
    "df['A'] = df['A'].astype(float)\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ba8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e783ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a902af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6359f9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97355b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f01d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be509416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd61315",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
